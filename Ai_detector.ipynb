{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "pktXRbrnjSJm"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "# from datasets import Dataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.nn.functional import softmax\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import pandas as pd\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Training_Essay_Data.csv')\n"
      ],
      "metadata": {
        "id": "Lk-agIoFjYX0"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "kDZIMRh7kR9t",
        "outputId": "a30cd434-2bb1-4533-f01a-a640c7202789"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text  generated\n",
              "0      Car-free cities have become a subject of incre...          1\n",
              "1      Car Free Cities  Car-free cities, a concept ga...          1\n",
              "2        A Sustainable Urban Future  Car-free cities ...          1\n",
              "3        Pioneering Sustainable Urban Living  In an e...          1\n",
              "4        The Path to Sustainable Urban Living  In an ...          1\n",
              "...                                                  ...        ...\n",
              "29140  There has been a fuss about the Elector Colleg...          0\n",
              "29141  Limiting car usage has many advantages. Such a...          0\n",
              "29142  There's a new trend that has been developing f...          0\n",
              "29143  As we all know cars are a big part of our soci...          0\n",
              "29144  Cars have been around since the 1800's and hav...          0\n",
              "\n",
              "[29145 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8648bd42-b048-471e-a37d-2b74034820c5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>generated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Car-free cities have become a subject of incre...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Car Free Cities  Car-free cities, a concept ga...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A Sustainable Urban Future  Car-free cities ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Pioneering Sustainable Urban Living  In an e...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Path to Sustainable Urban Living  In an ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29140</th>\n",
              "      <td>There has been a fuss about the Elector Colleg...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29141</th>\n",
              "      <td>Limiting car usage has many advantages. Such a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29142</th>\n",
              "      <td>There's a new trend that has been developing f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29143</th>\n",
              "      <td>As we all know cars are a big part of our soci...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29144</th>\n",
              "      <td>Cars have been around since the 1800's and hav...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29145 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8648bd42-b048-471e-a37d-2b74034820c5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8648bd42-b048-471e-a37d-2b74034820c5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8648bd42-b048-471e-a37d-2b74034820c5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c30179a4-d6a9-4140-80b5-35ef8a289d9c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c30179a4-d6a9-4140-80b5-35ef8a289d9c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c30179a4-d6a9-4140-80b5-35ef8a289d9c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_0945f67a-c772-4c94-80c4-cffa068c689b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0945f67a-c772-4c94-80c4-cffa068c689b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 29145,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27340,\n        \"samples\": [\n          \"There is no definitive answer when it comes to determining which skill of English is more important for Chinese learners. Some people may feel that reading is more important, as it allows learners to gain a deeper understanding of the language and it's nuances. Others may feel that speaking is more important, as it allows learners to use the language in a real-world setting and to improve their fluency. Ultimately, it is up to the individual learner to decide which skill they want to focus on more.\\n\\nThere are a number of reasons why reading may be more important for Chinese learners. First, reading allows learners to develop a more in-depth understanding of the language. By reading extensively, learners can learn new vocabulary words and expressions, and they can also learn about the different cultures that use English. Additionally, reading can help learners improve their grammar and writing skills.\\n\\nSecond, reading can help learners improve their listening skills. When learners read a text, they are not just listening to the words that are being spoken, they are also listening to the way the words are being spoken. This can help learners improve their ability to understand English when it is spoken in real-world situations.\\n\\nFinally, reading can help learners improve their overall vocabulary. By reading extensively, learners will be exposed to a variety of different words and expressions. This can help them improve their vocabulary skills and their ability to use English correctly.\\n\\nThere are a number of reasons why speaking may be more important for Chinese learners. First, speaking allows learners to use the language in a real-world setting. This can help them improve their fluency and their ability to communicate effectively in English. Additionally, speaking can help learners strengthen their pronunciation skills.\\n\\nSecond, speaking can help learners build their confidence in using the language. When learners speak English, they are able to see how the language works in real-world situations. This can help them feel more confident in their ability to use the language and to communicate with others.\\n\\nFinally, speaking can help learners learn more about the culture of the English-speaking world. When learners speak with native English speakers, they are able to learn more about the culture and the way that people in the English-speaking world think and behave. This can help learners better understand the culture and the people who use the language.\\n\\nIn conclusion, there is no definitive answer when it comes to determining which skill of English is more important for Chinese learners. Some people may feel that reading is more important, while others may feel that speaking is more important. Ultimately, it is up to the individual learner to decide which skill they want to focus on more.\\n\\n\",\n          \"When someone is looking for advice, they might want to get more than one opinion. This is because different people have different experiences and perspectives. By talking to multiple people, you can get a better understanding of the situation and make a more informed decision.\\n\\nFor example, let's say you are trying to decide which college to attend. If you only talk to one person, they might have a limited perspective based on their own experiences. However, if you talk to several people, you can get a variety of opinions and insights. You might talk to a college counselor who can give you information on the application process and financial aid, a current student who can tell you about their experiences on campus, and a graduate who can give you advice on career opportunities after graduation. By gathering all of this information, you can make a more informed decision about which college is the best fit for you.\\n\\nIn addition, seeking multiple opinions can help you avoid making a decision based on bias or limited information. If you only talk to one person, they might have their own biases or preferences that could influence their advice. However, by talking to multiple people, you can get a more well-rounded perspective and make a decision based on a variety of factors.\\n\\nOverall, seeking multiple opinions can be a helpful way to make a better choice. It allows you to gather more information, consider different perspectives, and make a more informed decision.\",\n          \"According to the text I think is a good idea that students can graduate from high school in three years because if you graduate from high school very early you are going to get a lot of opportunities to be successful in life, I also think that if someone decide to start working contraction or hard works like that early, three years later that person going to get a lot of experience and money and if you decide go to college or some like that when you graduate from college you going to be young and ready for life, that's how a lot of people became millinery, because the must time you spend doing something that's more experience that you going to get, and when you got experience and you know what you doing, and what you want you life going to be better and easier in the future.\\n\\nPeople also think that it is a bad idea graduate from high school in three years because they said that is to early, and you don't going to be smart enough to be successful in life but I said \\\" that's wrong because we still have to go to summer school and take extra classes in summer school and you have to be very smart because you need to pass all you classes you cannot fail any class because if you fail one you need to take it in summer school again and that's going to be a problem so if you want to graduate early you also have to take classes online so you're going to be very busy so they should be ready for the next level.\\n\\nI know someone that he is from Dominican Republic but he leaves in Generic_City, I went to one of his barbershop and i ask him\\n\\n\\\" what did you do to be so successful? he told me this \\\" when i was 16 years old I graduate from high school' then i ask \\\"how you graduate so early and he told me that he take classes in summer school and he take classes online\\\" i said that' s good \\\"keep telling me how you became succesfull \\\" and he told me that after he graduate he went to college to take classes the barbershop 3 years later he was only 19 years old so he have to work for one year if he want to open his own busyness then after that he open three barbershops in Generic_City he said if you put you best effort to the thing you, and life going to get better everything.\\n\\nAnother thing is that not everybody make it,\\n\\nis hard but i have i tip for those type of people never give up just do you best and put you hurt to it and put you best effort because at the and your mom and dad don't going to be there to pay for you food you going to be the man in that house so that's why everybody need to work hard everyday if they one to be successful in life.\\n\\nIn conclusion the best thing for student in graduate early because the must experience you get doing something the must money you going make and for me life is about perseverance, progress, and be successful because if you don' got nothing nobody going to respect you, and you need to help the people that cannot make it because people fail sometime life is not that easy for some people is you got the opportunity to do it good in life take that opportunity.               \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"generated\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FunQZ8BekVRw",
        "outputId": "80b6cc18-38d9-4089-d81d-afef7bb5a4f6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29145, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "V5ol3L1hkYOA",
        "outputId": "2a7e40f5-c026-4c0c-fe2a-e97497f04f78"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text         0\n",
              "generated    0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>generated</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'].duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hutouqzgka7O",
        "outputId": "31577352-3d67-40b7-9ec6-d92b166825bb"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1805"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(subset=['text'],inplace=True)"
      ],
      "metadata": {
        "id": "fbydNjlBkdDr"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaygIHKbkr48",
        "outputId": "b675c504-6544-4e08-91d5-205323d4a3cf"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27340, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "-X7ip4GWkxjd",
        "outputId": "3aa30154-92a0-4550-c500-2f2d3c3ffaca"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text         0\n",
              "generated    0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>generated</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "def encode_intent(text):\n",
        "    \"\"\"Tokenizes text and returns input IDs & attention mask.\"\"\"\n",
        "    encoding = bert_tokenizer(text, truncation=True, padding=\"max_length\", max_length=256, return_tensors=\"pt\")\n",
        "    return encoding[\"input_ids\"].squeeze(), encoding[\"attention_mask\"].squeeze()\n"
      ],
      "metadata": {
        "id": "iN5w_FwZk3wi"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []"
      ],
      "metadata": {
        "id": "d2XgJ2tOnEvq"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in df['text']:\n",
        "  data.append(encode_intent(x))"
      ],
      "metadata": {
        "id": "voUdSMuAmtiP"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "1_FYVb56rzZ-"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data, df['generated'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "24HGkFnSsAwQ"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n"
      ],
      "metadata": {
        "id": "OE6gwJP5T46W"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self, X_train,labels):\n",
        "\n",
        "    self.X_train = X_train\n",
        "    self.labels=labels\n",
        "\n",
        "  def __len__(self):\n",
        "\n",
        "    return len(self.labels)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    input_ids, attention_mask = self.X_train[index]  # Unpack tuple\n",
        "    return input_ids, attention_mask, self.labels[index]\n"
      ],
      "metadata": {
        "id": "O0x1-OQcpae4"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = torch.tensor(y_train.values, dtype=torch.long)\n"
      ],
      "metadata": {
        "id": "cqRX9jTtZ5GL"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxl6UxX8YxPy",
        "outputId": "b853d307-389c-4f3e-852d-79ef97839144"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([  101,  4442, 11640,  2031,  2019,  7461,  2006,  3071,  1005,  1055,\n",
              "          2166,  1012,  2111,  2224,  2037,  3526,  3042,  2005,  2471,  2673,\n",
              "          2107,  2004,  1024,  3793,  2075,  1010,  3331,  1010,  4041,  2477,\n",
              "          1010,  4385,  1012,  2070,  2111,  2064,  2079,  1037,  2843,  2007,\n",
              "          2037,  3526,  3042,  1999,  2037,  2192,  1012,  3071,  2003,  2467,\n",
              "          4208,  2006,  2037,  3042,  2138, 11640,  2024,  2590,  2000,  3071,\n",
              "          1012,  2108,  2006,  3526, 11640,  2096,  4439,  2003,  1037,  3809,\n",
              "          3808,  3891,  1012,  2043,  2115,  2006,  2115,  3526,  3042,  2096,\n",
              "          4439,  2017,  5293,  2008,  2115,  4439,  2138,  2115,  2667,  2000,\n",
              "          3793,  1012,  2108,  2006,  3526, 11640,  2096,  4439,  2003,  2025,\n",
              "          3647,  2017,  2064,  2031,  1037,  2482,  5823,  1998,  3480,  1996,\n",
              "          2060,  2711,  2017,  2718,  1012,  2087,  1997,  2482, 19119,  2272,\n",
              "          2013,  2043,  2111,  2006,  2037,  3042,  1998,  2025,  7079,  3086,\n",
              "          2000,  4439,  1012,  2009,  2003,  2200,  4795,  2005,  3071,  2065,\n",
              "          2017,  2022,  2006,  2115,  3526,  3042,  2096,  4439,  1012,  6853,\n",
              "          2323,  2025,  2022,  3039,  2000,  2022,  2006,  3526, 11640,  2096,\n",
              "          4439,  1012,  6853,  3046,  2000,  3298,  1998,  3793,  2012,  1996,\n",
              "          2168,  2051,  1998,  2008,  1005,  1055,  2129,  2111,  2131,  3480,\n",
              "          1012,  2065,  6853,  2024,  2025,  3039,  2000,  2224,  2037,  3042,\n",
              "          2009,  2097,  2393,  2000,  2025,  2031,  2061,  2116, 13436,  1012,\n",
              "          3793,  2075,  1998,  4439,  2003,  2028,  1997,  1996,  2087,  4795,\n",
              "          2477,  2000,  2079,  2006,  1996,  2346,  1012,  2151, 11116,  4439,\n",
              "          2064,  2131,  2017,  1999,  4926,  2138,  2115,  2025,  4208,  2006,\n",
              "          4439,  1012,  3793,  2075,  1998,  4439,  2003,  2074,  2066,  5948,\n",
              "          1998,  4439,  2009,  1005,  1055,  2200,  4795,  1012, 10126,  2009,\n",
              "          1005,  1055,  1037,  2482,  4926,   102]),\n",
              " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=CustomDataset(X_train,y_train)\n",
        "train_loader=DataLoader(dataset,batch_size=16,shuffle=True)"
      ],
      "metadata": {
        "id": "9Dk9K9JPpqoM"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW\n"
      ],
      "metadata": {
        "id": "mm4IBthJWb4R"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "w3enr8XcaCr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load Model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "bert_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2).to(device)\n",
        "\n",
        "# Optimizer & Mixed Precision Scaling\n",
        "optimizer = AdamW(bert_model.parameters(), lr=5e-5, weight_decay=0.01)\n",
        "scaler = torch.cuda.amp.GradScaler()  # Enables Mixed Precision for speed\n",
        "\n",
        "# Training Loop\n",
        "epochs = 3\n",
        "bert_model.train()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        input_ids, attention_mask, labels = [x.to(device, non_blocking=True) for x in batch]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Mixed Precision Training\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = bert_model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "\n",
        "        # Backpropagation with Gradient Clipping\n",
        "        scaler.scale(loss).backward()\n",
        "        torch.nn.utils.clip_grad_norm_(bert_model.parameters(), 1.0)  # Prevent gradient explosion\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1} completed. Avg Loss: {total_loss / len(train_loader):.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COqf41devXwL",
        "outputId": "d26053db-5eae-4cf3-ba59-da57953f1d61"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "<ipython-input-83-f6454150cd8b>:7: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()  # Enables Mixed Precision for speed\n",
            "<ipython-input-83-f6454150cd8b>:21: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 completed. Avg Loss: 0.4986\n",
            "Epoch 2 completed. Avg Loss: 0.1012\n",
            "Epoch 3 completed. Avg Loss: 0.0532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "bert_model.save_pretrained(\"AI_DETECTOR\")\n",
        "bert_tokenizer.save_pretrained(\"AI_DETECTOR\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQMWBYwrq7sD",
        "outputId": "51911da6-e1ff-40d1-bbdd-250e5eb9d0a6"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('AI_DETECTOR/tokenizer_config.json',\n",
              " 'AI_DETECTOR/special_tokens_map.json',\n",
              " 'AI_DETECTOR/vocab.txt',\n",
              " 'AI_DETECTOR/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r AI_DETECTOR.zip AI_DETECTOR\n"
      ],
      "metadata": {
        "id": "UjTnzfspCH2b",
        "outputId": "daf706f9-839a-4705-859e-f8058380483c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: AI_DETECTOR/ (stored 0%)\n",
            "  adding: AI_DETECTOR/config.json (deflated 49%)\n",
            "  adding: AI_DETECTOR/tokenizer_config.json (deflated 75%)\n",
            "  adding: AI_DETECTOR/model.safetensors (deflated 7%)\n",
            "  adding: AI_DETECTOR/special_tokens_map.json (deflated 42%)\n",
            "  adding: AI_DETECTOR/vocab.txt (deflated 53%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "file_path = \"AI_DETECTOR.zip\"\n",
        "file_size = os.path.getsize(file_path)  # Size in bytes\n",
        "print(f\"File Size: {file_size / (1024 * 1024):.2f} MB\")  # Convert to MB\n"
      ],
      "metadata": {
        "id": "KE-ikRKtJgHg",
        "outputId": "a11dc20f-11b0-4097-d393-36aa884d8c64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File Size: 386.58 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/AI_DETECTOR /content/drive/MyDrive/AI/\n"
      ],
      "metadata": {
        "id": "bPPVXNs-f5w1"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/AI/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0e4H7z3f-ba",
        "outputId": "c1b373b1-70c1-4323-f5f6-0c876650e36f"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.json  model.safetensors\tspecial_tokens_map.json  tokenizer_config.json\tvocab.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "# Load Model & Tokenizer from Saved Directory\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "bert_model = BertForSequenceClassification.from_pretrained(\"AI_DETECTOR\").to(device)\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(\"AI_DETECTOR\")\n",
        "\n",
        "bert_model.eval()  # Set model to evaluation mode\n",
        "\n",
        "def encode_intent(text):\n",
        "    \"\"\"Tokenizes text and returns input IDs & attention mask.\"\"\"\n",
        "    encoding = bert_tokenizer(text, truncation=True, padding=\"max_length\", max_length=256, return_tensors=\"pt\")\n",
        "    return encoding[\"input_ids\"].squeeze(), encoding[\"attention_mask\"].squeeze()\n",
        "\n",
        "def predict(text):\n",
        "    \"\"\"Predicts whether a given text is AI-generated or human-written with confidence scores.\"\"\"\n",
        "    input_ids, attention_mask = encode_intent(text)\n",
        "\n",
        "    input_ids = input_ids.unsqueeze(0).to(device)\n",
        "    attention_mask = attention_mask.unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        probs = F.softmax(logits, dim=1).squeeze().cpu().numpy()  # Apply softmax\n",
        "\n",
        "    ai_confidence = probs[1] * 100  # Probability of AI-generated class\n",
        "    human_confidence = probs[0] * 100  # Probability of Human-written class\n",
        "\n",
        "    return f\"ðŸ”¹ AI-Generated: {ai_confidence:.2f}% | ðŸ”¹ Human-Written: {human_confidence:.2f}%\"\n",
        "\n",
        "# ðŸ”¹ Predict on a Sample Text\n",
        "sample_text = '''Artificial intelligence has revolutionized multiple industries, enhancing efficiency and decision-making. Large language models, such as GPT and BERT, enable natural language processing at an unprecedented scale. These models analyze vast amounts of textual data, generating human-like responses. However, concerns regarding AI-generated misinformation and ethical considerations continue to emerge. As AI advances, responsible usage and regulation become critical for maintaining credibility and transparency in digital communications.'''\n",
        "\n",
        "print(\"Prediction:\", predict(sample_text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ON3cT80Fx5Yx",
        "outputId": "752f2d8e-9155-4421-a6ce-6bfe221e457d"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: ðŸ”¹ AI-Generated: 100.00% | ðŸ”¹ Human-Written: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[0][0].type()"
      ],
      "metadata": {
        "id": "s3_4CbHz71GZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "1WDxayO8kuBy"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert `y_test` properly\n",
        "if isinstance(y_test, pd.Series):  # If y_test is a Pandas Series, convert it to NumPy\n",
        "    y_test = y_test.reset_index(drop=True)  # Reset index to avoid KeyError\n",
        "\n",
        "# Prepare Test Data\n",
        "input_ids, attention_masks = [], []\n",
        "for i in range(len(X_test)):\n",
        "    input_ids.append(X_test[i][0])  # Extract input_ids\n",
        "    attention_masks.append(X_test[i][1])  # Extract attention_mask\n",
        "\n",
        "# Create DataLoader\n",
        "batch_size = 16\n",
        "test_dataset = CustomDataset(X_test, y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Evaluate Model\n",
        "bert_model.eval()\n",
        "all_preds, all_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
        "\n",
        "        outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
        "        preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
        "\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Calculate Accuracy\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "KJp_-vpb5sP0",
        "outputId": "4adc9890-740c-41f2-dacb-43c370afe9ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9771\n"
          ]
        }
      ]
    }
  ]
}